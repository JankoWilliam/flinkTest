Flink programs are regular programs that implement transformations on distributed
collections (e.g., filtering, mapping, updating state, joining, grouping, defining
windows, aggregating). Collections are initially created from sources (e.g., by reading
from files, kafka topics, or from local, in-memory collections). Results are returned
via sinks, which may for example write the data to (distributed) files, or to standard
output (for example, the command line terminal). Flink programs run in a variety of contexts,
standalone, or embedded in other programs. The execution can happen in a local JVM, or on clusters of many machines.

Depending on the type of data sources, i.e. bounded or unbounded sources, you would either
write a batch program or a streaming program where the DataSet API is used for batch and
the DataStream API is used for streaming. This guide will introduce the basic concepts
that are common to both APIs but please see our Streaming Guide and Batch Guide for concrete
information about writing programs with each API.